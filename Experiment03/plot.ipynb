{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_l0 = \"Color_L0_Relative\\metrics\"\n",
    "shape_l0 = \"ShapeWorld_L0\\metrics\"\n",
    "col_s0 = \"Color_S0\\metrics\"\n",
    "shape_s0 = \"ShapeWorld_S0\\metrics\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train process plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col_L0_accs_epoch(path,ids,epoch_num):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "    axs[0].set_title(\"Simple L0\")\n",
    "    axs[0].set_xlabel(\"epoch\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        acc = np.array(acc).mean(axis=0)\n",
    "        axs[0].plot(range(1,epoch_num+1),acc[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    axs[0].set_ylim([0.25,0.8])\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title(\"BERT-CLS L0\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        acc = np.array(acc).mean(axis=0)\n",
    "        axs[1].plot(range(1,epoch_num+1),acc[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    axs[1].set_ylim([0.25,0.8])\n",
    "    axs[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_shape_L0_accs_epoch(path,ids,epoch_num):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "    axs[0].set_title(\"Simple L0\")\n",
    "    axs[0].set_xlabel(\"epoch\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        acc = np.array(acc).mean(axis=0)\n",
    "        axs[0].plot(range(1,epoch_num+1),acc[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    axs[0].set_ylim([0.25,1.0])\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title(\"BERT-CLS L0\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        acc = np.array(acc).mean(axis=0)\n",
    "        axs[1].plot(range(1,epoch_num+1),acc[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    axs[1].set_ylim([0.25,1.0])\n",
    "    axs[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 5\n",
    "plot_col_L0_accs_epoch(col_l0,ids,epoch)\n",
    "plot_shape_L0_accs_epoch(shape_l0,ids,epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col_s0_accs_epoch(path,acc_type,ids,epoch_num):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "    axs[0].set_title(\"Original-RNN S0\")\n",
    "    axs[0].set_xlabel(\"epoch\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        accs = []\n",
    "        for id in range(1,ids+1):\n",
    "            if acc_type==\"L0\": acc = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")[2]\n",
    "            else: acc = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")[3]\n",
    "            accs.append(acc)\n",
    "        accs = np.array(accs).mean(axis=0)\n",
    "        axs[0].plot(range(1,epoch_num+1),accs[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    if acc_type==\"L0\":\n",
    "        axs[0].set_ylim([0.25,0.9])\n",
    "    else:\n",
    "        axs[0].set_ylim([0.0,0.7])\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title(\"All-fine-tuned GPT2 S0\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        accs = []\n",
    "        for id in range(1,ids+1):\n",
    "            if acc_type==\"L0\": acc = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")[2]\n",
    "            else: acc = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")[3]\n",
    "            accs.append(acc)\n",
    "        accs = np.array(accs).mean(axis=0)\n",
    "        axs[1].plot(range(1,epoch_num+1),accs[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    if acc_type==\"L0\":\n",
    "        axs[1].set_ylim([0.25,0.9])\n",
    "    else:\n",
    "        axs[1].set_ylim([0.0,0.7])\n",
    "    axs[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 3\n",
    "print(\"L0\")\n",
    "plot_col_s0_accs_epoch(col_s0,acc_type=\"L0\",ids=ids,epoch_num=epoch)\n",
    "print(\"L1\")\n",
    "plot_col_s0_accs_epoch(col_s0,acc_type=\"L1\",ids=ids,epoch_num=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape_s0_accs_epoch(path,acc_type,ids,epoch_num):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10,4))\n",
    "    axs[0].set_title(\"Original-RNN S0\")\n",
    "    axs[0].set_xlabel(\"epoch\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        accs = []\n",
    "        for id in range(1,ids+1):\n",
    "            if acc_type==\"L0\": acc = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")[2]\n",
    "            else: acc = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")[3]\n",
    "            accs.append(acc)\n",
    "        accs = np.array(accs).mean(axis=0)\n",
    "        axs[0].plot(range(1,epoch_num+1),accs[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    if acc_type==\"L0\":\n",
    "        axs[0].set_ylim([0.25,0.7])\n",
    "    else:\n",
    "        axs[0].set_ylim([0.25,0.8])\n",
    "    axs[0].legend()\n",
    "    axs[1].set_title(\"All-fine-tuned GPT2 S0\")\n",
    "    axs[1].set_xlabel(\"epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        accs = []\n",
    "        for id in range(1,ids+1):\n",
    "            if acc_type==\"L0\": acc = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")[2]\n",
    "            else: acc = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")[3]\n",
    "            accs.append(acc)\n",
    "        accs = np.array(accs).mean(axis=0)\n",
    "        axs[1].plot(range(1,epoch_num+1),accs[:epoch_num],color=col,label=\"data size=\"+str(size))\n",
    "    if acc_type==\"L0\":\n",
    "        axs[1].set_ylim([0.25,0.7])\n",
    "    else:\n",
    "        axs[1].set_ylim([0.25,0.8])\n",
    "    axs[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 3\n",
    "print(\"L0\")\n",
    "plot_shape_s0_accs_epoch(shape_s0,acc_type=\"L0\",ids=ids,epoch_num=epoch)\n",
    "print(\"L1\")\n",
    "plot_shape_s0_accs_epoch(shape_s0,acc_type=\"L1\",ids=ids,epoch_num=epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train size VS accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col_L0_accs_size(path,ids,epoch_num):\n",
    "    plt.figure()\n",
    "    plt.title(\"Data size VS Accuracy\")\n",
    "    plt.xlabel(\"Data size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    base_accs = []\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        base_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[10,50,250,1250,6250,31250])),base_accs,color=\"b\",label=\"Simple L0\")\n",
    "    bert_accs = []\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        bert_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[10,50,250,1250,6250,31250])),bert_accs,color=\"r\",label=\"BERT-CLS L0\")\n",
    "    plt.ylim([0.25,0.8])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_shape_L0_accs_size(path,ids,epoch_num):\n",
    "    plt.figure()\n",
    "    plt.title(\"Data size VS Accuracy\")\n",
    "    plt.xlabel(\"Data size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    base_accs = []\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        base_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[15,60,250,1000,4000])),base_accs,color=\"b\",label=\"Simple L0\")\n",
    "    bert_accs = []\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            acc.append(metrics[-1])\n",
    "        bert_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[15,60,250,1000,4000])),bert_accs,color=\"r\",label=\"BERT-CLS L0\")\n",
    "    plt.ylim([0.25,1.0])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 5\n",
    "plot_col_L0_accs_size(col_l0,ids,epoch)\n",
    "plot_shape_L0_accs_size(shape_l0,ids,epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ids=5\n",
    "path = shape_l0\n",
    "\n",
    "base_acc250 = []\n",
    "base_acc4000 = []\n",
    "bert_acc250 = []\n",
    "bert_acc4000 = []\n",
    "for id in range(1,ids+1):\n",
    "    base_acc250.append(max(np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(250)+\"_ID=\"+str(id)+\".npy\")[-1]))\n",
    "    base_acc4000.append(max(np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(4000)+\"_ID=\"+str(id)+\".npy\")[-1]))\n",
    "    bert_acc250.append(max(np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(250)+\"_ID=\"+str(id)+\".npy\")[-1]))\n",
    "    bert_acc4000.append(max(np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(4000)+\"_ID=\"+str(id)+\".npy\")[-1]))\n",
    "print(base_acc250)\n",
    "print(bert_acc250)\n",
    "print(base_acc4000)\n",
    "print(bert_acc4000)\n",
    "\n",
    "\n",
    "print(stats.ttest_ind(base_acc250,bert_acc250))\n",
    "print(stats.ttest_ind(base_acc4000,bert_acc4000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ids=5\n",
    "path = shape_l0\n",
    "\n",
    "base_acc250 = []\n",
    "bert_acc250 = []\n",
    "for id in range(1,ids+1):\n",
    "    acc250 = np.load(path+\"/Baseline/baseline-l0_trainSize=\"+str(250)+\"_ID=\"+str(id)+\".npy\")[-1]\n",
    "    e = 0\n",
    "    for acc in acc250:\n",
    "        if acc>0.7:\n",
    "            e+=1\n",
    "            break\n",
    "        e+=1\n",
    "    base_acc250.append(e)\n",
    "    bertacc250 = np.load(path+\"/BERT/BERT-CLS-l0_trainSize=\"+str(250)+\"_ID=\"+str(id)+\".npy\")[-1]\n",
    "    e = 0\n",
    "    for acc in bertacc250:\n",
    "        if acc>0.7:\n",
    "            e+=1\n",
    "            break\n",
    "        e+=1\n",
    "    bert_acc250.append(e)\n",
    "\n",
    "print(base_acc250)\n",
    "print(bert_acc250)\n",
    "print(stats.ttest_ind(base_acc250,bert_acc250))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_col_S0_accs_size(type,path,ids,epoch_num):\n",
    "    plt.figure()\n",
    "    plt.title(\"Data size VS Accuracy\")\n",
    "    plt.xlabel(\"Data size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    base_accs = []\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            if type==\"L0\":\n",
    "                acc.append(metrics[2])\n",
    "            else:\n",
    "                acc.append(metrics[3])\n",
    "        base_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[10,50,250,1250,6250,31250])),base_accs,color=\"b\",label=\"Original-RNN S0\")\n",
    "    bert_accs = []\n",
    "    for size,col in zip([10,50,250,1250,6250,31250],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_ID=\"+str(id)+\".npy\")\n",
    "            if type==\"L0\":\n",
    "                acc.append(metrics[2])\n",
    "            else:\n",
    "                acc.append(metrics[3])\n",
    "        bert_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[10,50,250,1250,6250,31250])),bert_accs,color=\"r\",label=\"All-fine-tuned GPT-2 S0\")\n",
    "    plt.ylim([0.25,0.9])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 3\n",
    "plot_col_S0_accs_size(\"L0\",col_s0,ids,epoch)\n",
    "plot_col_S0_accs_size(\"L1\",col_s0,ids,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shape_S0_accs_size(type,path,ids,epoch_num):\n",
    "    plt.figure()\n",
    "    plt.title(\"Data size VS Accuracy\")\n",
    "    plt.xlabel(\"Data size\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    base_accs = []\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")\n",
    "            if type==\"L0\":\n",
    "                acc.append(metrics[2])\n",
    "            else:\n",
    "                acc.append(metrics[3])\n",
    "        base_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[15,60,250,1000,4000])),base_accs,color=\"b\",label=\"Original-RNN S0\")\n",
    "    bert_accs = []\n",
    "    for size,col in zip([15,60,250,1000,4000],[\"b\",\"r\",\"g\",\"y\",\"m\",\"c\"]):\n",
    "        acc = []\n",
    "        for id in range(1,ids+1):\n",
    "            metrics = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(size)+\"_epoch=50_ID=\"+str(id)+\".npy\")\n",
    "            if type==\"L0\":\n",
    "                acc.append(metrics[2])\n",
    "            else:\n",
    "                acc.append(metrics[3])\n",
    "        bert_accs.append(max(np.array(acc).mean(axis=0)[:epoch_num]))\n",
    "    plt.plot(list(map(str,[15,60,250,1000,4000])),bert_accs,color=\"r\",label=\"All-fine-tuned GPT-2 S0\")\n",
    "    plt.ylim([0.35,0.75])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 30\n",
    "ids = 3\n",
    "plot_shape_S0_accs_size(\"L0\",shape_s0,ids,epoch)\n",
    "plot_shape_S0_accs_size(\"L1\",shape_s0,ids,epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "ids=3\n",
    "path = shape_s0\n",
    "base_acc_small = []\n",
    "base_acc_large = []\n",
    "bert_acc_small = []\n",
    "bert_acc_large = []\n",
    "for id in range(1,ids+1):\n",
    "    base_acc_small.append(max(np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(250)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-2]))\n",
    "    base_acc_large.append(max(np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(4000)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-2]))\n",
    "    bert_acc_small.append(max(np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(250)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-2]))\n",
    "    bert_acc_large.append(max(np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(4000)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-2]))\n",
    "print(stats.ttest_ind(base_acc_small,bert_acc_small))\n",
    "print(stats.ttest_ind(base_acc_large,bert_acc_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "ids=3\n",
    "path = shape_s0\n",
    "\n",
    "base_acc250 = []\n",
    "bert_acc250 = []\n",
    "for id in range(1,ids+1):\n",
    "    acc250 = np.load(path+\"/Baseline/baseline-s0_trainSize=\"+str(250)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-1]\n",
    "    e = 0\n",
    "    for acc in acc250:\n",
    "        if acc>0.55:\n",
    "            e+=1\n",
    "            break\n",
    "        e+=1\n",
    "    base_acc250.append(e)\n",
    "    bertacc250 = np.load(path+\"/GPT2/gpt2-s0_trainSize=\"+str(250)+\"_epoch=50_ID=\"+str(id)+\".npy\")[-1]\n",
    "    e = 0\n",
    "    for acc in bertacc250:\n",
    "        if acc>0.55:\n",
    "            e+=1\n",
    "            break\n",
    "        e+=1\n",
    "    bert_acc250.append(e)\n",
    "\n",
    "print(base_acc250)\n",
    "print(bert_acc250)\n",
    "print(stats.ttest_ind(base_acc250,bert_acc250))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
