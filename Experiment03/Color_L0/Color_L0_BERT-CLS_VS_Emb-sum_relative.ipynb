{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from functools import reduce\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from corpus import ColorsCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device = \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.path.abspath('')).parent.parent.parent.absolute()\n",
    "data_path = os.path.join(root,\"data\")\n",
    "print(data_path)\n",
    "corpus = ColorsCorpusReader(os.path.join(data_path,\"colors.csv\"), word_count=None, normalize_colors=True)\n",
    "examples = list(corpus.read())\n",
    "print(\"Number of datapoints: {}\".format(len(examples)))\n",
    "# balance positive and negative samples\n",
    "colors_data = [e.get_context_data()[0] for e in examples]\n",
    "utterance_data = [e.get_context_data()[1] for e in examples]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for Normal L0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章を単語IDの系列データに変換\n",
    "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
    "def sentence2index(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return [vocab_dict[w] for w in tokens]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if not os.path.exists(\"vocab.pkl\"):\n",
    "    # generate vocab dict\n",
    "    print(\"Generating vocab dict ...\")\n",
    "    vocab_list = list(set(reduce(lambda x,y:x+y,[word_tokenize(c) for c in utterance_data]))) # with nltk.tokenizer, 3953 vocabs\n",
    "    vocab_list = [\"<pad>\"] + vocab_list                                                     # Added padding for batching\n",
    "    vocab_dict = dict(zip(vocab_list,list(range(len(vocab_list)))))\n",
    "    with open('vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(vocab_dict, f)\n",
    "else:\n",
    "    print(\"Loading vocab dict ...\")\n",
    "    with open('vocab.pkl', 'rb') as f:\n",
    "        vocab_dict = pickle.load(f)\n",
    "print(\"Length of the Vocab list is \",len(vocab_dict.keys()))\n",
    "print(\"<pad> id = \",vocab_dict[\"<pad>\"])\n",
    "print(\"<sos> id = \",vocab_dict[\"<sos>\"])\n",
    "print(\"<eos> id = \",vocab_dict[\"<eos>\"])\n",
    "print(\"<unk> id = \",vocab_dict[\"<unk>\"])\n",
    "print(\"blue id = \",vocab_dict[\"blue\"])\n",
    "print(\"red id = \",vocab_dict[\"red\"])\n",
    "print(\"green id = \",vocab_dict[\"green\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepapre test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "colors_data_tensor = torch.tensor(np.array(colors_data),dtype=torch.float)\n",
    "context_id_data = list(map(sentence2index,utterance_data))\n",
    "max_context_len = max([len(c) for c in context_id_data])\n",
    "padded_context_data = torch.tensor(np.array([[1]+c+[2]+[0]*(max_context_len-len(c)) for c in context_id_data]))   # <sos>+context+<eos>+<pad>*\n",
    "print(\"Colors shape = \",colors_data_tensor.shape)\n",
    "print(\"Padded context id lists shape = \",padded_context_data.shape)\n",
    "\n",
    "data = [(color,torch.tensor(context,dtype=torch.long)) for color,context in zip(colors_data_tensor,padded_context_data)]\n",
    "labels = torch.zeros(len(data),3)\n",
    "labels[:,2] = 1.0\n",
    "print(\"total data length = \",len(data))\n",
    "print(\"total label shape = \",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = -1000   # 45994:1000\n",
    "test_x, test_y = data[test_num:], labels[test_num:]\n",
    "test_x, test_y = data, labels\n",
    "test_dataset = list(zip(test_x,test_y))\n",
    "print(\"test dataset length: \",len(test_dataset))\n",
    "test_batch = DataLoader(dataset=test_dataset,batch_size=128,shuffle=False,num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for pre-trained LLM L0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Bert word embedding model\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # casedは大文字小文字区別なし\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states=True)\n",
    "emb_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vector(sentence):\n",
    "    print(sentence)\n",
    "    marked_sents = \"[CLS] \"+sentence+\" [SEP]\"\n",
    "    tokens = tokenizer.tokenize(marked_sents)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    bert_model.to(device)\n",
    "    bert_model.eval()\n",
    "    with torch.no_grad(): outputs = bert_model(tokens_tensor)\n",
    "    vecs = outputs[0]\n",
    "    return vecs[0],tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "colors_data_tensor = torch.tensor(np.array(colors_data),dtype=torch.float)\n",
    "if not os.path.exists(\"tmp/all_contexts_embs_46994x33x768.tensor\"):\n",
    "    context_vecs = [c[0] for c in list(map(sentence2vector,utterance_data))]\n",
    "    max_context_len = max([len(c) for c in context_vecs])\n",
    "    padded_context_data = torch.vstack(tuple([torch.vstack((c.to(\"cpu\"),torch.zeros(max_context_len-len(c),emb_dim))) for c in context_vecs]))\n",
    "else:\n",
    "    print(\"Context Padded Tensor is loaded...\")\n",
    "    padded_context_data = torch.load(\"tmp/all_contexts_embs_46994x33x768.tensor\")\n",
    "    padded_context_data = padded_context_data.view(-1,33,emb_dim)\n",
    "print(\"Colors shape = \",colors_data_tensor.shape)\n",
    "print(\"Padded context id lists shape = \",padded_context_data.shape)\n",
    "\n",
    "sentence_vecs = torch.vstack(tuple([vecs[0] for vecs in padded_context_data]))\n",
    "print(\"CLS vector data:, \",sentence_vecs.shape)\n",
    "bert_data = [(color,torch.tensor(context,dtype=torch.float)) for color,context in zip(colors_data_tensor,sentence_vecs)]\n",
    "labels = torch.zeros(len(bert_data),3)\n",
    "labels[:,2] = 1.0\n",
    "print(\"total data length = \",len(bert_data))\n",
    "print(\"total label shape = \",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = -1000\n",
    "test_x, test_y = bert_data[test_num:], labels[test_num:]\n",
    "test_dataset = list(zip(test_x,test_y))\n",
    "print(\"test dataset length: \",len(test_dataset))\n",
    "bert_test_batch = DataLoader(dataset=test_dataset,batch_size=128,shuffle=False,num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Normal L0 Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "def train_model(model,train_batch,criterion,optimizer,do_break=False):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    #print(\"Start Training\")\n",
    "    for data,label in train_batch:\n",
    "        colors, contexts = data[0].to(device), data[1].to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(colors,contexts)\n",
    "        loss = criterion(y_pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred_label = y_pred.argmax(1)\n",
    "        correct_label = label.argmax(1)\n",
    "        train_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "        if do_break: break\n",
    "    batch_train_loss = train_loss/len(train_batch)\n",
    "    batch_train_acc = train_acc/len(train_batch)\n",
    "    return batch_train_loss, batch_train_acc\n",
    "\n",
    "def eval_model(model,test_batch,criterion,do_break=False):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data,label in test_batch:\n",
    "            colors, contexts = data[0].to(device), data[1].to(device)\n",
    "            label = label.to(device)\n",
    "            y_pred = model(colors,contexts)\n",
    "            test_loss += criterion(y_pred,label).item()\n",
    "            pred_label = y_pred.argmax(1)\n",
    "            correct_label = label.argmax(1)\n",
    "            test_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "            if do_break: break\n",
    "    batch_test_loss = test_loss/len(test_batch)\n",
    "    batch_test_acc = test_acc/len(test_batch)\n",
    "    return batch_test_loss, batch_test_acc\n",
    "\n",
    "\n",
    "def train_and_eval_epochs(model,criterion,optimizer,epoch,train_batch,test_batch,train_size,log=True,do_break=False):\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "    for i in range(epoch):\n",
    "        if log:\n",
    "            print(\"##############################################\")\n",
    "            print(\"Epoch:{}/{}\".format(i+1,epoch))\n",
    "        batch_train_loss, batch_train_acc = train_model(model,train_batch,criterion,optimizer,do_break=do_break)\n",
    "        batch_test_loss, batch_test_acc = eval_model(model,test_batch,criterion,do_break=do_break)\n",
    "        if log:\n",
    "            print(\"Train Loss:{:.2E}, Test Loss:{:.2E}\".format(batch_train_loss,batch_test_loss))\n",
    "            print(\"Train Acc:{:.2E}, Test Acc:{:.2E}\".format(batch_train_acc,batch_test_acc))\n",
    "        train_loss_list.append(batch_train_loss)\n",
    "        test_loss_list.append(batch_test_loss)\n",
    "        train_acc_list.append(batch_train_acc)\n",
    "        test_acc_list.append(batch_test_acc)\n",
    "        if batch_test_loss < best_loss:\n",
    "            if log: print(\"Best Loss saved ...\")\n",
    "            torch.save(model.to(device).state_dict(),\"model_params/Baseline/baseline-l0_best-loss_trainSize=\"+str(train_size)+\".pth\")\n",
    "            best_loss = batch_test_loss\n",
    "        if batch_test_acc > best_acc:\n",
    "            if log: print(\"Best Acc saved ...\")\n",
    "            torch.save(model.to(device).state_dict(),\"model_params/Baseline/baseline-l0_best-acc_trainSize=\"+str(train_size)+\".pth\")\n",
    "            best_acc = batch_test_acc\n",
    "        if do_break: break\n",
    "    return train_loss_list,test_loss_list,train_acc_list,test_acc_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from color_literal_listener import Simple_L0\n",
    "criterion = nn.MSELoss()\n",
    "epoch = 30\n",
    "# train size up to 80000\n",
    "for train_num in [10,50,250,1250,6250,31250]:\n",
    "    # train_batch\n",
    "    print(\"Train data size = \",train_num)\n",
    "    train_x, train_y = data[:train_num], labels[:train_num]\n",
    "    train_dataset = list(zip(train_x,train_y))\n",
    "    train_batch = DataLoader(dataset=train_dataset,batch_size=128,shuffle=True,num_workers=0)\n",
    "    # model setting\n",
    "    model = Simple_L0(len(vocab_dict)).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    # train and eval with epoch\n",
    "    tr_loss,ts_loss,tr_acc,ts_acc = train_and_eval_epochs(model,criterion,optimizer,epoch,train_batch,test_batch,train_size=train_num,log=True,do_break=True)\n",
    "    metrics = np.array([tr_loss,ts_loss,tr_acc,ts_acc])\n",
    "    np.save(\"metrics/Baseline/baseline-l0_trainSize=\"+str(train_num)+\"_test.npy\",metrics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare BERT-CLS L0 model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "def train_model(model,train_batch,criterion,optimizer,do_break=False):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    #print(\"Start Training\")\n",
    "    for data,label in train_batch:\n",
    "        colors, contexts = data[0].to(device), data[1].to(device)\n",
    "        label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(colors,contexts)\n",
    "        loss = criterion(y_pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred_label = y_pred.argmax(1)\n",
    "        correct_label = label.argmax(1)\n",
    "        train_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "        if do_break: break\n",
    "    batch_train_loss = train_loss/len(train_batch)\n",
    "    batch_train_acc = train_acc/len(train_batch)\n",
    "    return batch_train_loss, batch_train_acc\n",
    "\n",
    "def eval_model(model,test_batch,criterion,do_break=False):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data,label in test_batch:\n",
    "            colors, contexts = data[0].to(device), data[1].to(device)\n",
    "            label = label.to(device)\n",
    "            y_pred = model(colors,contexts)\n",
    "            test_loss += criterion(y_pred,label).item()\n",
    "            pred_label = y_pred.argmax(1)\n",
    "            correct_label = label.argmax(1)\n",
    "            test_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "            if do_break: break\n",
    "    batch_test_loss = test_loss/len(test_batch)\n",
    "    batch_test_acc = test_acc/len(test_batch)\n",
    "    return batch_test_loss, batch_test_acc\n",
    "\n",
    "\n",
    "def train_and_eval_epochs(model,criterion,optimizer,epoch,train_batch,test_batch,train_size,log=True,do_break=False):\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "    for i in range(epoch):\n",
    "        if log:\n",
    "            print(\"##############################################\")\n",
    "            print(\"Epoch:{}/{}\".format(i+1,epoch))\n",
    "        batch_train_loss, batch_train_acc = train_model(model,train_batch,criterion,optimizer,do_break=do_break)\n",
    "        batch_test_loss, batch_test_acc = eval_model(model,test_batch,criterion,do_break=do_break)\n",
    "        if log:\n",
    "            print(\"Train Loss:{:.2E}, Test Loss:{:.2E}\".format(batch_train_loss,batch_test_loss))\n",
    "            print(\"Train Acc:{:.2E}, Test Acc:{:.2E}\".format(batch_train_acc,batch_test_acc))\n",
    "        train_loss_list.append(batch_train_loss)\n",
    "        test_loss_list.append(batch_test_loss)\n",
    "        train_acc_list.append(batch_train_acc)\n",
    "        test_acc_list.append(batch_test_acc)\n",
    "        if batch_test_loss < best_loss:\n",
    "            if log: print(\"Best Loss saved ...\")\n",
    "            torch.save(model.to(device).state_dict(),\"model_params/BERT/bert-cls-l0_best-loss_trainSize=\"+str(train_size)+\".pth\")\n",
    "            best_loss = batch_test_loss\n",
    "        if batch_test_acc > best_acc:\n",
    "            if log: print(\"Best Acc saved ...\")\n",
    "            torch.save(model.to(device).state_dict(),\"model_params/BERT/bert-cls-l0_best-acc_trainSize=\"+str(train_size)+\".pth\")\n",
    "            best_acc = batch_test_acc\n",
    "        if do_break: break\n",
    "    return train_loss_list,test_loss_list,train_acc_list,test_acc_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from color_literal_listener import BERT_Sent_L0\n",
    "criterion = nn.MSELoss()\n",
    "epoch = 30\n",
    "# train size up to 80000\n",
    "for train_num in [10,50,250,1250,6250,31250]:\n",
    "    # train_batch\n",
    "    print(\"Train data size = \",train_num)\n",
    "    train_x, train_y = bert_data[:train_num], labels[:train_num]\n",
    "    train_dataset = list(zip(train_x,train_y))\n",
    "    train_batch = DataLoader(dataset=train_dataset,batch_size=128,shuffle=True,num_workers=0)\n",
    "    # model setting\n",
    "    model = BERT_Sent_L0(hidden_dim=emb_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    # train and eval with epoch\n",
    "    tr_loss,ts_loss,tr_acc,ts_acc = train_and_eval_epochs(model,criterion,optimizer,epoch,train_batch,bert_test_batch,train_size=train_num,log=True,do_break=True)\n",
    "    metrics = np.array([tr_loss,ts_loss,tr_acc,ts_acc])\n",
    "    np.save(\"metrics/BERT/BERT-CLS-l0_trainSize=\"+str(train_num)+\"_test.npy\",metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
