{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from shapeworld_data import load_raw_data, get_vocab, ShapeWorld"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Images Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.path.abspath('')).parent.parent.absolute()\n",
    "data_path = os.path.join(root,\"data\\shapeworld_np\")\n",
    "print(data_path)\n",
    "data_list = os.listdir(data_path)\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for data in data_list:\n",
    "    d = load_raw_data(os.path.join(data_path,data))\n",
    "    img_set = d[\"imgs\"].reshape(-1,3,64,64)\n",
    "    imgs.append(img_set)\n",
    "imgs_data = np.array(imgs).reshape(-1,3,64,64)\n",
    "print(imgs_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = -1000\n",
    "train_set = imgs_data[:split]\n",
    "test_set = imgs_data[split:]\n",
    "batch_size = 128\n",
    "trainloader = DataLoader(torch.tensor(train_set).to(torch.float), batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(torch.tensor(test_set).to(torch.float), batch_size=batch_size // 10, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "    print(data.shape)\n",
    "    #print(data)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = torchvision.utils.make_grid(img)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.detach().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, epochs, trainloader, device=\"cpu\"):\n",
    "    losses = []\n",
    "    output_and_label = []\n",
    "    net = net.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'epoch: {epoch}, ', end='')\n",
    "        running_loss = 0.0\n",
    "        for counter, img in enumerate(trainloader, 1):\n",
    "            img = img.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(img)\n",
    "            #print(output.shape,img.shape)\n",
    "            loss = criterion(output, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / counter\n",
    "        losses.append(avg_loss)\n",
    "        print('loss:', avg_loss)\n",
    "        output_and_label.append((output, img))\n",
    "    print('finished')\n",
    "    return output_and_label, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder2(torch.nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc1 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, 3, padding=1),  # [-1, 16, 32, 32]\n",
    "    #torch.nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),  # [-1, 16, 16, 16]\n",
    "    torch.nn.Conv2d(16, 32, 3, padding=1),  # [-1, 8, 16, 16]\n",
    "    #torch.nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2)  # [-1, 8, 8, 8]\n",
    ")\n",
    "\n",
    "dec1 = torch.nn.Sequential(\n",
    "    torch.nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(16, 3, kernel_size=2, stride=2),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = AutoEncoder2(enc1, dec1)\n",
    "net1.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net1.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "output_and_label1, losses1 = train(net1, criterion, optimizer, EPOCHS, trainloader,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, org = output_and_label1[-1]\n",
    "imshow(org.to(\"cpu\"))\n",
    "imshow(img.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net1.enc,\"model_params/cnn_autoencoder3-16-32.cnnet\")\n",
    "torch.save(net1,\"model_params/cnn_autoenc-dec3-16-32.cnnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, img in enumerate(testloader, 1):\n",
    "    img = img.to(device)\n",
    "    output = net1(img)\n",
    "    print(output.shape,img.shape)\n",
    "    imshow(img.to(\"cpu\"))\n",
    "    imshow(output.to(\"cpu\"))\n",
    "    if counter>4: break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 16, kernel_size=4, padding=1, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(16, 32, kernel_size=4, padding=1, stride=2),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "\n",
    "dec2 = torch.nn.Sequential(\n",
    "    torch.nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = AutoEncoder2(enc2, dec2)\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net2.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "output_and_label2, losses2 = train(net2, criterion, optimizer, EPOCHS, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, org = output_and_label2[-1]\n",
    "imshow(org)\n",
    "imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc3 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    ")\n",
    "\n",
    "dec3 = torch.nn.Sequential(\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(64, 3, kernel_size=2, stride=3, padding=1),\n",
    "    torch.nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = AutoEncoder2(enc3, dec3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net3.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "#output_and_label3, losses3 = train(net3, criterion, optimizer, EPOCHS, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img, org = output_and_label3[-1]\n",
    "#imshow(org)\n",
    "#imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc4 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    ")\n",
    "\n",
    "dec4 = torch.nn.Sequential(\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "    torch.nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4 = AutoEncoder2(enc4, dec4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net4.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "#output_and_label4, losses4 = train(net4, criterion, optimizer, EPOCHS, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img, org = output_and_label4[-1]\n",
    "#imshow(org)\n",
    "#imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc5 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n",
    "    #torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    #torch.nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    #torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    #torch.nn.ReLU(inplace=True),\n",
    "    #torch.nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n",
    "    #torch.nn.ReLU(inplace=True),\n",
    ")\n",
    "\n",
    "dec5 = torch.nn.Sequential(\n",
    "    #torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    #torch.nn.ReLU(inplace=True),\n",
    "    #torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    #torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(inplace=True),\n",
    "    torch.nn.ConvTranspose2d(64, 3, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net5 = AutoEncoder2(enc5, dec5)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net5.parameters())\n",
    "EPOCHS = 10\n",
    "\n",
    "output_and_label4, losses4 = train(net5, criterion, optimizer, EPOCHS, trainloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, org = output_and_label4[-1]\n",
    "imshow(org.to(\"cpu\"))\n",
    "imshow(img.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net5.enc,\"model_params/cnn_autoencoder3-64-64_ver3.cnnet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model read test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder = torch.load(\"model_params/cnn_autoencoder3-64-64.cnnet\")\n",
    "cnn_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, img in enumerate(trainloader, 1):\n",
    "    img = img.to(device)\n",
    "    output = cnn_encoder(img)\n",
    "    print(output.shape,img.shape)\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
