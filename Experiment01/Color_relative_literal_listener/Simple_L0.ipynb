{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from corpus import ColorsCorpusReader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2index(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return [vocab_dict[w] for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(os.path.abspath('')).parent.parent.absolute()\n",
    "data_path = os.path.join(root,\"data\")\n",
    "print(data_path)\n",
    "corpus = ColorsCorpusReader(os.path.join(data_path,\"colors.csv\"), word_count=None, normalize_colors=True)\n",
    "examples = list(corpus.read())\n",
    "print(\"Number of datapoints: {}\".format(len(examples)))\n",
    "# balance positive and negative samples\n",
    "colors_data = [e.get_context_data()[0] for e in examples]\n",
    "utterance_data = [e.get_context_data()[1] for e in examples]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pickle\n",
    "# generate vocab dict\n",
    "if not os.path.exists(\"vocab.pkl\"):\n",
    "    print(\"Generating vocab dict ...\")\n",
    "    vocab_list = list(set(reduce(lambda x,y:x+y,[word_tokenize(c) for c in utterance_data]))) # with nltk.tokenizer, 3953 vocabs\n",
    "    vocab_list = [\"<pad>\",\"<sos>\",\"<eos>\",\"<unk>\"] + vocab_list                               # Added padding for batching\n",
    "    vocab_dict = dict(zip(vocab_list,list(range(len(vocab_list)))))\n",
    "    with open('vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(vocab_dict, f)\n",
    "else:\n",
    "    print(\"Loading vocab dict ...\")\n",
    "    with open('vocab.pkl', 'rb') as f:\n",
    "        vocab_dict = pickle.load(f)\n",
    "print(\"Length of the Vocab list is \",len(vocab_dict.keys()))\n",
    "print(\"<pad> id = \",vocab_dict[\"<pad>\"])\n",
    "print(\"<sos> id = \",vocab_dict[\"<sos>\"])\n",
    "print(\"<eos> id = \",vocab_dict[\"<eos>\"])\n",
    "print(\"<unk> id = \",vocab_dict[\"<unk>\"])\n",
    "print(\"blue id = \",vocab_dict[\"blue\"])\n",
    "print(\"red id = \",vocab_dict[\"red\"])\n",
    "print(\"green id = \",vocab_dict[\"green\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "colors_data_tensor = torch.tensor(np.array(colors_data),dtype=torch.float)\n",
    "context_id_data = list(map(sentence2index,utterance_data))\n",
    "max_context_len = max([len(c) for c in context_id_data])\n",
    "padded_context_data = torch.tensor(np.array([[1]+c+[2]+[0]*(max_context_len-len(c)) for c in context_id_data]))   # <sos>+context+<eos>+<pad>*\n",
    "print(\"Colors shape = \",colors_data_tensor.shape)\n",
    "print(\"Padded context id lists shape = \",padded_context_data.shape)\n",
    "\n",
    "data = [(color,torch.tensor(context,dtype=torch.long)) for color,context in zip(colors_data_tensor,padded_context_data)]\n",
    "label = torch.zeros(len(data),3)\n",
    "label[:,2] = 1.0\n",
    "print(\"total data length = \",len(data))\n",
    "print(\"total label shape = \",label.shape)\n",
    "\n",
    "test_split = 7000\n",
    "train_data, test_data = data[:-test_split], data[-test_split:]\n",
    "train_label, test_label = label[:-test_split], label[-test_split:]\n",
    "print(\"Train, Test data length = \",len(train_data),\",\",len(test_data))\n",
    "print(\"Train, Test label length = \",len(train_label),\",\",len(test_label))\n",
    "\n",
    "train_dataset = list(zip(train_data,train_label))\n",
    "test_dataset = list(zip(test_data,test_label))\n",
    "train_batch = DataLoader(dataset=train_dataset,batch_size=128,shuffle=True,num_workers=0)\n",
    "test_batch = DataLoader(dataset=test_dataset,batch_size=128,shuffle=False,num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_L0(nn.Module):\n",
    "    def __init__(self,vocab_size, emb_dim=768, hidden_dim=100, output_dim=1) -> None:\n",
    "        super(Simple_L0,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = emb_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear01 = nn.Linear(3+emb_dim,hidden_dim)\n",
    "        self.linear02 = nn.Linear(hidden_dim,hidden_dim//2)\n",
    "        self.linear03 = nn.Linear(hidden_dim//2, output_dim)\n",
    "\n",
    "    def forward(self,color_rgbs, contexts):\n",
    "        embs = self.embedding(contexts)\n",
    "        hiddens = torch.sum(embs,dim=1).reshape(-1,self.embedding_dim)\n",
    "        y1 = self.linear03(F.relu(self.linear02(F.relu(self.linear01(torch.hstack((color_rgbs[:,0],hiddens)))))))\n",
    "        y2 = self.linear03(F.relu(self.linear02(F.relu(self.linear01(torch.hstack((color_rgbs[:,1],hiddens)))))))\n",
    "        y3 = self.linear03(F.relu(self.linear02(F.relu(self.linear01(torch.hstack((color_rgbs[:,2],hiddens)))))))\n",
    "        y_hat = F.softmax(torch.cat([y1,y2,y3],dim=1),dim=-1)\n",
    "        return y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_L0(len(vocab_dict)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epoch = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "best_loss = 100\n",
    "best_acc = 0\n",
    "for i in range(epoch):\n",
    "    print(\"##############################################\")\n",
    "    print(\"Epoch:{}/{}\".format(i+1,epoch))\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    for (cols,context),label in train_batch:\n",
    "        colors,context,label = cols.to(device), context.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(colors,context)\n",
    "        #print(y_pred.shape,label.shape)\n",
    "        loss = criterion(y_pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred_label = y_pred.argmax(1)\n",
    "        correct_label = label.argmax(1)\n",
    "        #print(pred_label.shape,correct_label.shape)\n",
    "        train_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "        #break\n",
    "    batch_train_loss = train_loss/len(train_batch)\n",
    "    batch_train_acc = train_acc/len(train_batch)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (cols,context),label in test_batch:\n",
    "            colors,context,label = cols.to(device), context.to(device), label.to(device)\n",
    "            y_pred = model(colors,context)\n",
    "            loss = criterion(y_pred,label)\n",
    "            test_loss += loss.item()\n",
    "            pred_label = y_pred.argmax(1)\n",
    "            correct_label = label.argmax(1)\n",
    "            test_acc += (sum(pred_label==correct_label)/len(correct_label)).item()\n",
    "            #break\n",
    "        batch_test_loss = test_loss/len(test_batch)\n",
    "        batch_test_acc = test_acc/len(test_batch)\n",
    "\n",
    "    print(\"Train Loss:{:.2E}, Test Loss:{:.2E}\".format(batch_train_loss,batch_test_loss))\n",
    "    print(\"Train Acc:{:.2E}, Test Acc:{:.2E}\".format(batch_train_acc,batch_test_acc))\n",
    "    train_loss_list.append(batch_train_loss)\n",
    "    test_loss_list.append(batch_test_loss)\n",
    "    train_acc_list.append(batch_train_acc)\n",
    "    test_acc_list.append(batch_test_acc)\n",
    "    if batch_test_loss < best_loss:\n",
    "        print(\"Best Loss saved: {:.2E}\".format(batch_test_loss))\n",
    "        torch.save(model.to(device).state_dict(),\"model_params/Simple-l0_epoch=\"+str(epoch)+\"_best-loss.pth\")\n",
    "        best_loss = batch_test_loss\n",
    "    if batch_test_acc > best_acc:\n",
    "        print(\"Best Acc saved: {:.2E}\".format(batch_test_acc))\n",
    "        torch.save(model.to(device).state_dict(),\"model_params/Simple-l0_epoch=\"+str(epoch)+\"_best-acc.pth\")\n",
    "        best_acc = batch_test_acc\n",
    "    #break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "pth = \"model_params/Simple-l0_epoch=\"+str(epoch)+\"_best-acc.pth\"\n",
    "model = Simple_L0(len(vocab_dict)).to(device)\n",
    "model.load_state_dict(torch.load(pth,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_acc(preds,labels):\n",
    "    score = []\n",
    "    for probs,label in zip(preds,labels):\n",
    "        if probs[0]==probs[1] and probs[1]==probs[2]: # all same\n",
    "            score.append(0.3)\n",
    "        elif (probs[0]==probs[1] and max(probs)==probs[0]) or (probs[1]==probs[2] and max(probs)==probs[1]) or (probs[0]==probs[2] and max(probs)==probs[1]):\n",
    "            score.append(0.5)\n",
    "        else:\n",
    "            predict = torch.argmax(probs)\n",
    "            correct = torch.argmax(label)\n",
    "            score.append(int(predict==correct))\n",
    "    #print(score)\n",
    "    return np.mean(score)\n",
    "\n",
    "def accuracy(model,test_batch,device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for (cols,context),label in test_batch:\n",
    "            colors,context,label = cols.to(device), context.to(device), label.to(device)\n",
    "            y_pred = model(colors,context)\n",
    "            test_acc += get_batch_acc(y_pred,label)\n",
    "        batch_test_acc = test_acc/len(test_batch)\n",
    "    return batch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(model,test_batch)\n",
    "print(\"Accuracy: \" + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
