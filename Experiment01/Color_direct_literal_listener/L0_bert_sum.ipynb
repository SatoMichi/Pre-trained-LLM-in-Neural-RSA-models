{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from corpus import ColorsCorpusReader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device = \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Bert word embedding model \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # casedは大文字小文字区別なし\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states=True)\n",
    "emb_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vector(sentence):\n",
    "    print(sentence)\n",
    "    marked_sents = \"[CLS] \"+sentence+\" [SEP]\"\n",
    "    tokens = tokenizer.tokenize(marked_sents)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    bert_model.to(device)\n",
    "    bert_model.eval()\n",
    "    with torch.no_grad(): outputs = bert_model(tokens_tensor)\n",
    "    vecs = outputs[0]\n",
    "    return vecs[0],tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare raw data\n",
    "root = Path(os.path.abspath('')).parent.parent.absolute()\n",
    "data_path = os.path.join(root,\"data\")\n",
    "print(data_path)\n",
    "corpus = ColorsCorpusReader(os.path.join(data_path,\"colors.csv\"), word_count=None, normalize_colors=True)\n",
    "examples = list(corpus.read())\n",
    "print(\"Number of datapoints: {}\".format(len(examples)))\n",
    "# balance positive and negative samples\n",
    "correct_color_data = [e.get_l0_data()[0] for e in examples]\n",
    "wrong_color_data = [e.get_l0_negative_data()[0] for e in examples]\n",
    "context_data = [e.get_l0_data()[1][0] for e in examples]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader and batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching\n",
    "correct_color_data_tensor = torch.tensor(np.array(correct_color_data),dtype=torch.float)\n",
    "wrong_color_data_tensor = torch.tensor(np.array(wrong_color_data),dtype=torch.float)\n",
    "if not os.path.exists(\"tmp/all_contexts_embs_46994x33x768.tensor\"):\n",
    "    context_vecs = [c[0] for c in list(map(sentence2vector,context_data))]\n",
    "    max_context_len = max([len(c) for c in context_vecs])\n",
    "    padded_context_data = torch.vstack(tuple([torch.vstack((c.to(\"cpu\"),torch.zeros(max_context_len-len(c),emb_dim))) for c in context_vecs]))\n",
    "    torch.save(padded_context_data,\"tmp/all_contexts_embs_46994x33x768.tensor\")\n",
    "else:\n",
    "    print(\"Context Padded Tensor is loaded...\")\n",
    "    padded_context_data = torch.load(\"tmp/all_contexts_embs_46994x33x768.tensor\")\n",
    "    padded_context_data = padded_context_data.view(-1,33,emb_dim)\n",
    "print(\"Color01 shape = \",correct_color_data_tensor.shape)\n",
    "print(\"Color02 shape = \",wrong_color_data_tensor.shape)\n",
    "print(\"Padded context id lists shape = \",padded_context_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "labels = torch.hstack((torch.ones(len(correct_color_data),dtype=torch.float),torch.zeros(len(wrong_color_data),dtype=torch.float)))\n",
    "color_data = torch.vstack((correct_color_data_tensor,wrong_color_data_tensor))\n",
    "token_sum_vecs = torch.vstack(tuple([torch.sum(vecs,dim=0) for vecs in padded_context_data]))\n",
    "sum_context_data = torch.vstack((token_sum_vecs,token_sum_vecs))\n",
    "print(\"Shape of labels = \",labels.shape,\"color data = \",color_data.shape,\"context data = \",sum_context_data.shape)\n",
    "# create data label pair\n",
    "sum_data = [(color,torch.tensor(context,dtype=torch.float)) for color,context in zip(color_data,sum_context_data)]\n",
    "print(\"total data length = \",len(sum_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and comstruct dataloader\n",
    "train_x, test_x, train_y, test_y = train_test_split(sum_data, labels, train_size=0.7)\n",
    "train_dataset = list(zip(train_x,train_y))\n",
    "test_dataset = list(zip(test_x,test_y))\n",
    "train_batch = DataLoader(dataset=train_dataset,batch_size=128,shuffle=True,num_workers=0)\n",
    "test_batch = DataLoader(dataset=test_dataset,batch_size=128,shuffle=False,num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color_Sent_BERT_L0(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim=100, output_dim=1):\n",
    "        super(Color_Sent_BERT_L0,self).__init__()\n",
    "        self.linear01 = nn.Linear(3+emb_dim,hidden_dim)\n",
    "        self.linear02 = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linear03 = nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "    def forward(self, color_rgb, context_embs):\n",
    "        #print(color_rgb.shape, context_embs.shape)\n",
    "        x = torch.hstack((color_rgb,context_embs))\n",
    "        x = F.relu(self.linear01(x))\n",
    "        x = F.relu(self.linear02(x))\n",
    "        x = F.relu(self.linear02(x))\n",
    "        y = self.linear03(x)\n",
    "        y_hat = torch.sigmoid(y)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Color_Sent_BERT_L0(emb_dim=emb_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epoch = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "best_loss = 100\n",
    "for i in range(epoch):\n",
    "    print(\"##############################################\")\n",
    "    print(\"Epoch:{}/{}\".format(i+1,epoch))\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    #print(\"Start Training\")\n",
    "    for data,label in train_batch:\n",
    "        colors = data[0].to(device)\n",
    "        contexts = data[1].to(device)\n",
    "        label = label.to(device)\n",
    "        #print(torch.sum(label))\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(colors,contexts)\n",
    "        #print(y_pred.shape,label.shape)\n",
    "        loss = criterion(y_pred,label.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    batch_train_loss = train_loss/len(train_batch)\n",
    "\n",
    "    model.eval()\n",
    "    #print(\"Start Evaluation\")\n",
    "    for data,label in test_batch:\n",
    "        colors = data[0].to(device)\n",
    "        contexts = data[1].to(device)\n",
    "        label = label.to(device)\n",
    "        #print(torch.sum(label))\n",
    "        y_pred = model(colors,contexts)\n",
    "        loss = criterion(y_pred,label.view(-1,1))\n",
    "        test_loss += loss.item()\n",
    "    batch_test_loss = test_loss/len(test_batch)\n",
    "\n",
    "    print(\"Train Loss:{:.2E}, Test Loss:{:.2E}\".format(batch_train_loss,batch_test_loss))\n",
    "    train_loss_list.append(batch_train_loss)\n",
    "    test_loss_list.append(batch_test_loss)\n",
    "    if batch_test_loss < best_loss:\n",
    "        torch.save(model.to(device).state_dict(),\"model_params/bert_sum_l0.pth\")\n",
    "        best_loss = batch_test_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Color_Sent_BERT_L0(emb_dim=emb_dim).to(device)\n",
    "model.load_state_dict(torch.load(\"model_params/bert_sum_l0.pth\",map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct = 0\n",
    "total_data = 0\n",
    "model.eval()\n",
    "#print(\"Start Evaluation\")\n",
    "for data,label in test_batch:\n",
    "    colors = data[0].to(device)\n",
    "    contexts = data[1].to(device)\n",
    "    label = label.to(device)\n",
    "    #print(label)\n",
    "    total_data += len(label)\n",
    "    #print(torch.sum(label))\n",
    "    y_pred = model(colors,contexts)\n",
    "    y_class = torch.where(y_pred>0.5,1,0).view(-1)\n",
    "    #print(y_class)\n",
    "    test_correct += torch.sum(y_class==label).item()\n",
    "print(\"Total number of data for this evaluatio is \",total_data)\n",
    "print(\"Classification accuracy is \",test_correct/total_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
